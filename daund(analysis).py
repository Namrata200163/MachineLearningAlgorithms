# -*- coding: utf-8 -*-
"""Daund(Analysis).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17NgpOOsbCDSGDdK1T2RHnCGwZf8OhOFe
"""

#@title Import required libraries

import numpy as np
import pandas as pd
from sklearn.impute import SimpleImputer
import statsmodels.api as sm
import matplotlib.pyplot as plt
import scipy.stats 
import statistics as stat
import seaborn as sns
sns.set_style("whitegrid")

#@title Import required dataset
import io
from google.colab import files 
uploaded=files.upload()

#@title Reading and subsetting dataset according to the requirements 
Data=pd.read_csv("Daund.csv")
Data["N"]=Data["Nanalyser"]
features=["pH","EC","OC","N","P","K"]
Data=Data[features]

#@title Imputation for Missing and Irrelevant Observations
def Imp(d1,d2,d3):
    Ideal = d1[(d1[d2] >= d3[0]) & (d1[d2] <= d3[1])]
    mean = sum(Ideal.loc[:,d2])/len(Ideal.loc[:,d2])
    Outlier=d1[(d1[d2] < d3[0])| (d1[d2] > d3[1]) |(d1[d2].isna())] 
    Outlier[d2]=mean
    df1 = pd.concat([Ideal,Outlier])
    return df1
df2 = Imp(Data,"pH",(4,10))
df3 = Imp(df2,"EC",(0.01,3))
df4 = Imp(df3,"OC",(0.01,4))
df5 = Imp(df4,"N",(100,850))
df6 = Imp(df5,"P",(3,65))
df7 = Imp(df6,"K",(40,1000))
Data=df7
datatoexcel = pd.ExcelWriter('Daund(Imputed) .xlsx')
  # write DataFrame to excel
Data.to_excel(datatoexcel)  
# save the excel
datatoexcel.save()
Data=pd.read_excel('Daund(Imputed) .xlsx')
Data.describe()

#Description of code - A function is created to impute the data variables so that outliers are imputed with median of the corresponding variable.

#@title Discretization of data variable into 5 levels 
def Category(d1,d2):
  d3=[]
  for i in range(0,len(d1)):
    if d1[i]<d2[0]:
       d3.insert(i,"Very Low")
    elif d1[i]<d2[1]:
        d3.insert(i,"Low")
    elif d1[i]<d2[2]:
        d3.insert(i,"Medium")
    elif d1[i]<d2[3]:
        d3.insert(i,"High")
    else:
        d3.insert(i,"Very High")
 
  return tuple(d3)
Data['N_discrete']=Category(Data['N'],(140,280,560,700))
Data
#Description of code- A function is created to transform data variable into 5 levels : Very Low , Low , Medium , High , Very High with respect to the ranges provided.

#@title To Remove Duplicated Rows 
features=["pH","EC","OC","N","P","K","N_discrete"]
Data1=Data[features]
Duplicate=Data1[Data1.duplicated()]
Distinct=Data.drop(Duplicate.index,axis=0)
features=["pH","EC","OC","N","P","K","N_discrete","Rainfall"]
Data=Distinct[features]
Data.duplicated().value_counts()
datatoexcel = pd.ExcelWriter('Daund(Processed).xlsx')
# write DataFrame to excel
Data.to_excel(datatoexcel)  
# save the excel
datatoexcel.save()
Data=pd.read_excel('Daund(Processed).xlsx')
# Remove unwanted column
Data.drop(["Unnamed: 0"],axis=1)

"""
#Exploratory Data Analysis
* EDA to find whether there is relationship between the variables is not advisible in our case. 
Because , even from the heatmap of correlations we already know that the scope for correlation among them is very low. 
Still, as we are ought to predict Nitrogen from other variables, we may have to use other tools in EDA.
* Objective of EDA -
>1. What is the soil nutrient status in DAUND taluka? 
 2. To find the interval for every parameter where maximum / minimum Nitrogen content is observed. 
 3. In what order the Nitrogen content in soil depends on pH,EC,OC,P,K (featureimportance)
 4. Summary statistics for all nutrients. 
 5. Is the analysis for done matching with the historical results?"""

#@title Histogram { vertical-output: true }
import seaborn
import matplotlib.pyplot as plt
plt.hist(Data['N'],50,color='green')
plt.xlabel('N')
plt.show()
plt.hist(Data['pH'],50,color='green')
plt.xlabel('pH')
plt.show()
plt.hist(Data['EC'],50,color='green')
plt.xlabel('EC')
plt.show()
plt.hist(Data['OC'],50,color='green')
plt.xlabel('OC')
plt.show()
plt.hist(Data['P'],50,color='green')
plt.xlabel('P')
plt.show()
plt.hist(Data['K'],50,color='green')
plt.xlabel('K')
plt.show()

#@title Distribution Plot
print(sns.displot(Data["pH"],kind="kde"))
print(sns.displot(Data["EC"],kind="kde"))
print(sns.displot(Data["OC"],kind="kde"))
print(sns.displot(Data["N"],kind="kde"))
print(sns.displot(Data["P"],kind="kde"))
print(sns.displot(Data["K"],kind="kde"))

#@title Skewness of data variables 
from scipy.stats import skew
print(skew(Data['N']))
print(skew(Data['OC']))
print(skew(Data['EC']))
print(skew(Data['pH']))
print(skew(Data['P']))
print(skew(Data['K']))

"""Interpretations from Histogram , Distribution plot and Skewness Measure -

1. Available Nitrogen content exhibits positive skewnes.
2. pH content seems to be more or less normally distributed.
3. Electric conductivity i.e EC exhibits high positive skewness.
4. Organic Carbon content exhibits positive skewnes.
5. Phosphorous content exhibits high positive skewness.
6. Potassium content exhibits positive skewnes.

(Note-The rule of thumb seems to be:
If the skewness is between -0.5 and 0.5, the data are fairly symmetrical
If the skewness is between -1 and â€“ 0.5 or between 0.5 and 1, the data are moderately skewed
If the skewness is less than -1 or greater than 1, the data are highly skewed)
"""

#@title Heatmap 
import seaborn as sns 
import matplotlib.pyplot as mp
sns.set(rc={'figure.figsize':(20,8)})
dataplot=sns.heatmap(Data[features].corr(),annot=True,annot_kws={'fontweight':'bold'})
mp.show()

#@title ExtraTreesClassifier Method (Feature Importance)
features=['EC','OC','pH','P','K']
x=Data[features]
y=Data['N_discrete']
from sklearn.ensemble import ExtraTreesClassifier
import matplotlib.pyplot as plt
model=ExtraTreesClassifier()
model.fit(x,y)
print(model.feature_importances_)
plt.figure(figsize=(8,6))
fit_importances=pd.Series(model.feature_importances_,index=x.columns)
fit_importances.nlargest().plot(kind="barh",color='mediumaquamarine')
plt.show()

#@title Countplot

def countplot(d1,d2,d3):
  new=Category(d1[d2],d3)
  df=pd.DataFrame(new)
  df.columns=[d2]
  plt.figure(figsize=(10,6))
  import seaborn as sns
  splot=sns.countplot(data=df,x=d2,order=["Very Low","Low","Medium","High","Very High"],palette="Greens")
  for p in splot.patches:
    percentage = '{:.1f}%'.format(100*p.get_height()/78828)
    splot.annotate(percentage, 
                   (p.get_x() + p.get_width() / 2., p.get_height()), 
                   ha = 'center', va = 'center', 
                   xytext = (0, 13), size=11,fontweight="bold",
                   textcoords = 'offset pixels')
    plt.ylabel("Number Of Soil Samples ", size=14)
    plt.savefig("add_text_to_top_of_bars_in_barplot_Seaborn_Python.png")
countplot(Data,"N",(140,280,560,700))
plt.xlabel("Availability Of Nitrogen(N) Content In Soil Samples ", size=14)
countplot(Data,"pH",(5.5,6.5,7.5,8.5))
plt.xlabel("Potential Of Hydrogen(pH) In Soil Samples ", size=14)
countplot(Data,"OC",(0.25,0.5,0.75,1))
plt.xlabel("Organic Carbon(OC) Content In Soil Samples ", size=14)
countplot(Data,"EC",(0.4,0.6,0.8,1))
plt.xlabel("Electric Conductivity(EC) Of Soil Samples ", size=14)
countplot(Data,"P",(5,10,25,40))
plt.xlabel("Phosphorus(P) Content In Soil Samples ", size=14)
countplot(Data,"K",(60,120,280,560))
plt.xlabel("Potassium(K) Content In Soil Samples ", size=14)

#@title Boxplots

def boxplots(d1,d2,d3,d4):
   Categorical_var=Category(d1[d2],d4)
   df=pd.DataFrame(Categorical_var,d1[d3])
   df=df.reset_index()
   sns.set(rc={'figure.figsize':(5,6)})
   sns.set_theme(style="whitegrid",palette="Pastel1") 
   boxplot_=sns.boxplot(df.iloc[:,1],df.iloc[:,0],data=df,linewidth=1,width=0.3,saturation=0.75,notch=True,order=["Very Low","Low","Medium","High","Very High"])
   boxplot_.set(xlabel=d2,ylabel=d3)
   plt.show()
   #plt.ylabel("Nitrogen Content", size=14)
boxplots(Data,"pH","N",(5.5,6.5,7.5,8.5))
plt.xlabel("potential of Hydrogen(pH)", size=14)
boxplots(Data,"EC","N",(0.4,0.6,0.8,1))
plt.xlabel("Electric Conductivity(EC)", size=14)
boxplots(Data,"OC","N",(0.25,0.5,0.75,1))
plt.xlabel("Organic Carbon(OC)", size=14)
boxplots(Data,"P","N",(5,10,25,40))
plt.xlabel("Phosphorus(P)", size=14)
boxplots(Data,"K","N",(60,120,280,560))
plt.xlabel("Potassium(K)", size=14)

#Description of code- A function is created to first make the concerned variable descrete and then to result into a boxplot.

"""# Regression 
  As the response variable is non normal , we cannot go for regression directly.
  We need to process the data first ! 
*  Ols regression can be used as their is not assumtion for normality of response.
[ Remark -
Checking assumtions for homoscedasticity :
Firstly do the regression analysis and then plot the error terms against the predicted values( Yi^). 
If there is a definite pattern (like linear or quadratic or funnel shaped) obtained from the scatter plot then heteroscedasticity is present
Using Goldfeld Quandt we test for heteroscedasticity.
Null Hypothesis: Error terms are homoscedastic
Alternative Hypothesis: Error terms are heteroscedastic  ]
"""

#@title Multiple Linear Regression using OLS models for whole Data 
features=['EC','OC','pH','P','K']
x=Data[features]
y=Data['N']
import statsmodels.api as sm 
m=sm.OLS(y,x).fit() 
print(m.summary())
sns.set(rc={'figure.figsize':(10,8)})
import matplotlib.pyplot as plt 
pred=m.predict(x)
res=y-pred
sm.qqplot(res)
plt.show()
plt.scatter(pred,res)
plt.show()

"""Observations - 
1. Residuals are not normal.
2. Residual plot is not random and Goldfeld Quandt test we reject null hypothesis and thus heteroscedasticity is present. 
3. CN is too high which suggests there is multicolinearity in the data.

Assumtions are not satisfied !
"""

#@title Decision Tree Classifier

features=['EC','OC','pH','P','K']
x=Data[features]
y=Data['N_discrete2']
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)
from sklearn.tree import DecisionTreeClassifier
Class=DecisionTreeClassifier(criterion="entropy")
Class.fit(x_train,y_train)
from sklearn.metrics import classification_report , confusion_matrix
print(classification_report(y_train,Class.predict(x_train)))
y_pred=Class.predict(x_test)
from sklearn.metrics._plot.confusion_matrix import confusion_matrix
from sklearn.metrics import classification_report , confusion_matrix
print(classification_report(y_test,y_pred))
print(Class.tree_.max_depth)

#@title Multinomial logistic regression
from sklearn.linear_model import LogisticRegression
features=['EC','OC','pH','P','K']
x=Data[features]
y=Data['N_discrete']
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)
model=LogisticRegression(multi_class='multinomial')
model.fit(x_train,y_train)
from sklearn.metrics import classification_report , confusion_matrix
print(classification_report(y_train,model.predict(x_train)))
print(classification_report(y_test,model.predict(x_test)))

"""## Feature Engineering 
* Feature Selection
>* Univariate feature selection works by selecting the best features based on univariate statistical tests. We compare each feature to the target variable, to see whether there is any statistically significant relationship between them. It is also called analysis of variance (ANOVA)
 * ExtraTrees Classifier can be used for classification or regression, in scenarios where computational cost is a concern and features have been carefully selected and analyzed. 
* Handling missing data 
* Handling Outliers 
* Handling imbalance data
 >* Imbalanced data refers to those types of datasets where the target class has an uneven distribution of observations, i.e one class label has a very high number of observations and the other has a very low number of observations.
 * Sometimes when the records of a certain class are much more than(called as majority class) the other class (called as minority class) , our classifier may get biased towards the prediction. 
 * The main problem with imbalanced dataset prediction is how accurately are we actually predicting both majority and minority class ! Model should not be biased to detect only the majority class but should give equal weight or importance towards the minority class too.
 * Thus our traditional approach of classification and model accuracy calculation is not useful in the case of the imbalanced dataset.
   **(Note- It is observed in analysis of Pune district data , that in every algorithm that is being deployed on the data gives more weightage to "Medium","Low" category of Nitrogen content. Thus in predictions , occurances of these two categories are quiet high than other levels !)**
* Feature Scaling
>* Real-world datasets often contain features that are varying in degrees of magnitude, range and units. Therefore, in order for machine learning models to interpret these features on the same scale, we need to perform feature scaling.
 * Some models (not all) are sensitive to scale, because they unjustly give more weight to features with bigger scales. Scaling here improves the model because it puts all features on the same scale, giving the model a better chance of finding the right patterns.
 * In our case , ranges for the parameter are from 0 to thousands ! Thus , this might also be a potential cause of failing of the models.
"""

#@title Imbalanced Data
plt.figure(figsize=(8, 6))
countplot(Data,"N",(140,280,560,700))
plt.xlabel("Availability Of Nitrogen(N) Content In Soil Samples ", size=14)
plt.ylabel("Number of soil samples", size=14)
plt.savefig("add_text_to_top_of_bars_in_barplot_Seaborn_Python.png")

#@title Handling Imbalance Data By UnderSampling
# 1.Under sampling of majority class (we may use oversampling also)
features=['EC','OC','pH','P','K']
x=Data[features]
y=Data['N_discrete']
plt.figure(figsize=(8,6))
from imblearn.under_sampling import RandomUnderSampler
sample=RandomUnderSampler()
x_undersampled,y_undersampled = sample.fit_resample(x,y)
#Countplot of new target variable
ax=sns.countplot(x=y_undersampled,order=["Very Low","Low","Medium","High","Very High"],palette="Greens")
plt.xticks(size=12)
plt.yticks(size=12)
def without_hue(plot, feature):
  total = len(feature)
  for p in ax.patches:
      percentage = '{:.1f}%'.format(100*p.get_height()/78828)  #78828 is the total number of obervations
      x = p.get_x() + p.get_width() 
      y = p.get_y() + p.get_height()
      ax.annotate(percentage, (x, y), size = 12)
  plt.xlabel("Availability Of Nitrogen(N) Content In Soil Samples ", size=14)
  plt.ylabel("Number of soil samples", size=14)
  plt.show()
  
without_hue(ax,y_undersampled)

#@title Handling Imbalance Data By OverSampling
# 1.Under sampling of majority class (we may use oversampling also)
features=['EC','OC','pH','P','K']
x=Data[features]
y=Data['N_discrete']
plt.figure(figsize=(8,6))
from imblearn.over_sampling import RandomOverSampler
sample=RandomOverSampler()
x_oversampled,y_oversampled = sample.fit_resample(x,y)
#Countplot of new target variable
ax=sns.countplot(x=y_oversampled,palette="Greens",order=["Very Low","Low","Medium","High","Very High"])
plt.xticks(size=12)
plt.yticks(size=12)
def without_hue(plot, feature):
  total = len(feature)
  for p in ax.patches:
      percentage = '{:.1f}%'.format(100*p.get_height()/78828)  #78828 is the total number of obervations
      x = p.get_x() + p.get_width() 
      y = p.get_y() + p.get_height() 
      ax.annotate(percentage, (x, y), size = 12)
      plt.xlabel("Availability Of Nitrogen(N) Content In Soil Samples ", size=14)
  plt.ylabel("Number of soil samples", size=14)
  plt.show()
without_hue(ax,y_oversampled)

#@title Decision Tree Classifier After UnderSampling

features=['EC','OC','pH','P','K']
x=Data[features]
y=Data['N_discrete']
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x_undersampled, y_undersampled, test_size=0.3)
from sklearn.tree import DecisionTreeClassifier
Class=DecisionTreeClassifier()
Class.fit(x_undersampled, y_undersampled)
from sklearn.metrics import classification_report , confusion_matrix
print(classification_report(y_undersampled,Class.predict(x_undersampled)))
y_pred=Class.predict(x)
from sklearn.metrics._plot.confusion_matrix import confusion_matrix
from sklearn.metrics import classification_report , confusion_matrix
print(classification_report(y,y_pred))

#@title Decision Tree Classifier After OverSampling 

features=['EC','OC','pH','P','K']
x=Data[features]
y=Data['N_discrete']
from imblearn.over_sampling import RandomOverSampler
sample=RandomOverSampler()
x_oversampled,y_oversampled = sample.fit_resample(x,y)
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x_oversampled, y_oversampled, test_size=0.3)
from sklearn.tree import DecisionTreeClassifier
Class=DecisionTreeClassifier(criterion="entropy")
Class.fit(x_train,y_train)
from sklearn.metrics import classification_report , confusion_matrix
print(classification_report(y_train,Class.predict(x_train)))
y_pred=Class.predict(x_test)
from sklearn.metrics._plot.confusion_matrix import confusion_matrix
from sklearn.metrics import classification_report , confusion_matrix
print(classification_report(y_test,y_pred))

#@title Multinomial logistic regression after oversampling
from imblearn.over_sampling import RandomOverSampler
sample=RandomOverSampler()
x_oversampled,y_oversampled = sample.fit_resample(x,y)
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x_oversampled,y_oversampled, test_size=0.3)
from sklearn.linear_model import LogisticRegression
model=LogisticRegression(multi_class='multinomial')
model.fit(x_train,y_train)
from sklearn.metrics import classification_report , confusion_matrix
print(classification_report(y_train,model.predict(x_train)))
print(classification_report(y_test,model.predict(x_test)))

#@title Feature Scaling for Oversampled data
from sklearn import preprocessing 
from sklearn.preprocessing import StandardScaler
scalar=preprocessing.StandardScaler()
oversampled_scaled = pd.DataFrame(scalar.fit_transform(x_oversampled), columns=x_oversampled.columns)  #fit and transforming StandardScaler the dataframe

#@title Decision Tree Classifier After OverSampling and feature scaling 

features=['EC','OC','pH','P','K']
x=Data[features]
y=Data['N_discrete']
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(oversampled_scaled, y_oversampled, test_size=0.3)
from sklearn.tree import DecisionTreeClassifier
Class=DecisionTreeClassifier()
Class.fit(x_train,y_train)
print(classification_report(y_train,Class.predict(x_train)))
y_pred=Class.predict(x_test)
from sklearn.metrics._plot.confusion_matrix import confusion_matrix
from sklearn.metrics import classification_report , confusion_matrix
print(classification_report(y_test,y_pred))

#@title Feature Scaling for Undersampled data
from sklearn import preprocessing 
from sklearn.preprocessing import StandardScaler
scalar=preprocessing.StandardScaler()
undersampled_scaled = pd.DataFrame(scalar.fit_transform(x_undersampled), columns=x_undersampled.columns)  #fit and transforming StandardScaler the dataframe

#@title Decision Tree Classifier After UnderSampling and feature scaling 

features=['EC','OC','pH','P','K']
x=Data[features]
y=Data['N_discrete']
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(undersampled_scaled, y_undersampled, test_size=0.3)
from sklearn.tree import DecisionTreeClassifier
Class=DecisionTreeClassifier()
Class.fit(x_train,y_train)
print(classification_report(y_train,Class.predict(x_train)))
y_pred=Class.predict(x_test)
from sklearn.metrics._plot.confusion_matrix import confusion_matrix
from sklearn.metrics import classification_report , confusion_matrix
print(classification_report(y_test,y_pred))

#@title Hyperparameter Tuning
from sklearn.linear_model import LogisticRegression
features=['EC','OC','pH','P','K']
x=Data[features]
y=Data['N_discrete']
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)
for max_d in range(1,21):
  model = DecisionTreeClassifier(max_depth=max_d, random_state=42)
  model.fit(x_train, y_train)
  print('The Training Accuracy for max_depth {} is:'.format(max_d), model.score(x_train, y_train))
  print('The Validation Accuracy for max_depth {} is:'.format(max_d), model.score(x_test,y_test))
  print('')

#@title Randomized Search CV on Decision tree 

features=['EC','OC','pH','P','K']
x=Data[features]
y=Data['N_discrete']
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y , test_size=0.3)
# Necessary imports
from scipy.stats import randint
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import RandomizedSearchCV
 
# Creating the hyperparameter grid
param_dist = {"max_depth": randint(12,20),
              "max_features": randint(1, 9),
              "min_samples_leaf": randint(1, 9)}
 
# Instantiating Decision Tree classifier
tree = DecisionTreeClassifier()
 
# Instantiating RandomizedSearchCV object
tree_cv = RandomizedSearchCV(tree, param_dist)
 
tree_cv.fit(x_train, y_train)
 
# Print the tuned parameters and score
print("Tuned Decision Tree Parameters: {}".format(tree_cv.best_params_))
print("Best score is {}".format(tree_cv.best_score_))

#@title Random forest
x=Data[features]
y=Data['N_discrete']
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)
from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier()
model.fit(x_train,y_train)
from sklearn.metrics import classification_report , confusion_matrix
print(classification_report(y_train,model.predict(x_train)))
print(classification_report(y_test,model.predict(x_test)))

#@title Decision Tree Classifier - Max_Depth parameter tuning 

features=['EC','OC','pH','P','K']
x=Data[features]
y=Data['N_discrete']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(x,y , test_size=0.3)

# define lists to collect scores
train_scores, test_scores = list(), list()
# define the tree depths to evaluate
values = [i for i in range(1, 50,2)]
# evaluate a decision tree for each depth
for i in values:
 # configure the model
 from sklearn.tree import DecisionTreeClassifier
 model = DecisionTreeClassifier(max_depth=i,random_state=42)
 # fit model on the training dataset
 model.fit(X_train, y_train)
 # evaluate on the train dataset
 train_yhat = model.predict(X_train)
 from sklearn.metrics import accuracy_score
 train_acc = accuracy_score(y_train, train_yhat)
 train_scores.append(train_acc)
 # evaluate on the test dataset
 test_yhat = model.predict(X_test)
 test_acc = accuracy_score(y_test, test_yhat)
 test_scores.append(test_acc)
 # summarize progress
 print('>%d, train: %.3f, test: %.3f' % (i, train_acc, test_acc))
import matplotlib.pyplot as pyplot
pyplot.plot(values, train_scores, '-o', label='Train')
pyplot.plot(values, test_scores, '-o', label='Test')
plt.xlabel("Maximum_Depth", size=14)
plt.ylabel("Accuracy", size=14)
pyplot.legend()
pyplot.show()

#@title Randomised search CV with Decision Tree Classifier Parameters 
features=['EC','OC','pH','P','K']
x=Data[features]
y=Data['N_discrete2']
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3)
# Necessary imports
from scipy.stats import randint
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import RandomizedSearchCV
 
# Creating the hyperparameter grid
param_dist = {"splitter":["best","random"],
            "max_depth" : [1,3,5,7,9,11,12,13,14,15,16,17,18,19,20,21,22,23,24,26,27,28,25,29,30],
           "min_samples_leaf":[1,2,3,4,5,6,7,8,9,10],
           "max_features":["auto",None],
           "max_leaf_nodes":[None,10,20,30,40,50,60,70,80,90] }
# Instantiating Decision Tree classifier
tree = DecisionTreeClassifier()
 
# Instantiating RandomizedSearchCV object
tree_cv = RandomizedSearchCV(tree, param_dist)
 
tree_cv.fit(x_train, y_train)
 
# Print the tuned parameters and score
print("Tuned Decision Tree Parameters: {}".format(tree_cv.best_params_))
print("Best score is {}".format(tree_cv.best_score_))

#@title Fitting of tuned model using Randomised search CV 

features=['EC','OC','pH','P','K']
x=Data[features]
y=Data['N_discrete2']
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3)

from sklearn.tree import DecisionTreeClassifier
Class=DecisionTreeClassifier(splitter= 'best',  min_samples_leaf= 5, max_leaf_nodes= None, max_features= 'auto', max_depth= 16)
Class.fit(x_train,y_train)
print(classification_report(y_train,Class.predict(x_train)))
y_pred=Class.predict(x_test)
from sklearn.metrics._plot.confusion_matrix import confusion_matrix
from sklearn.metrics import classification_report , confusion_matrix
print(classification_report(y_test,y_pred))

"""# **THANK YOU !**"""